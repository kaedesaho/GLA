{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77da553",
   "metadata": {
    "id": "f77da553"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3182632",
   "metadata": {
    "id": "b3182632"
   },
   "source": [
    "#### one gla: 11727303 sets 14153438 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebabee5",
   "metadata": {
    "id": "1ebabee5"
   },
   "outputs": [],
   "source": [
    "ft = fasttext.load_model('../cc.gd.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa00f736",
   "metadata": {
    "id": "fa00f736"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"gd\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "nlp.max_length = 7000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed77acc",
   "metadata": {
    "id": "2ed77acc"
   },
   "outputs": [],
   "source": [
    "with open(\"gla_dictionary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gaelic_words = set(line.strip() for line in f if line.strip() != \"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf5eb00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bf5eb00",
    "outputId": "1ee152ba-ee07-410a-ebc3-6222132ca523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "467b8389",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "467b8389",
    "outputId": "4e9b4b26-4d74-400c-b0bb-5b2259a07029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total .txt files found: 151\n"
     ]
    }
   ],
   "source": [
    "def get_txt_file_paths(folder):\n",
    "    txt_files = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                txt_files.append(os.path.join(root, file))\n",
    "    return txt_files\n",
    "\n",
    "file_paths = get_txt_file_paths(\"gla_books\")\n",
    "print(f\"Total .txt files found: {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95884f79",
   "metadata": {
    "id": "95884f79"
   },
   "outputs": [],
   "source": [
    "def tokenization(data):\n",
    "    doc = nlp(data)\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_space]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bc90e8c",
   "metadata": {
    "id": "5bc90e8c"
   },
   "outputs": [],
   "source": [
    "def get_gaelic_sentences(text, gaelic_words, min_length=2, excluded_words=None):\n",
    "    if excluded_words is None:\n",
    "        excluded_words = {\"a\", \"i\", \"an\", \"is\", \"do\", \"so\"}\n",
    "\n",
    "    doc = nlp(text)\n",
    "    gaelic_sents = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        tokens = [token.text.lower() for token in sent if token.is_alpha]\n",
    "        for token in tokens:\n",
    "            if token in gaelic_words and token not in excluded_words:\n",
    "                gaelic_sents.append(sent.text.strip())\n",
    "                break\n",
    "    return gaelic_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7723923",
   "metadata": {
    "id": "e7723923"
   },
   "outputs": [],
   "source": [
    "class GlaDataset(Dataset):\n",
    "    def __init__(self, file_paths, gaelic_words, context_size=5):\n",
    "        self.pairs = []\n",
    "\n",
    "        for path in file_paths:\n",
    "            with open(path, encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                sentences = get_gaelic_sentences(text, gaelic_words)\n",
    "                for sent in sentences:\n",
    "                    tokens = tokenization(sent)\n",
    "                    if len(tokens) > context_size:\n",
    "                            for i in range(context_size, len(tokens)):\n",
    "                                context = tokens[i - context_size:i]\n",
    "                                target = tokens[i]\n",
    "                                self.pairs.append((context, target))\n",
    "    def  __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.pairs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb7029ea",
   "metadata": {
    "id": "fb7029ea"
   },
   "outputs": [],
   "source": [
    "dataset = GlaDataset(file_paths, gaelic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5696c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 1_000_000\n",
    "remaining = len(dataset) - subset_size\n",
    "one_million, _ = random_split(dataset, [subset_size, remaining])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f32480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"one_million.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx in one_million.indices:\n",
    "        context, target = dataset[idx]\n",
    "        f.write(json.dumps({\"context\": context, \"target\": target}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8942adce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8942adce",
    "outputId": "ff802674-0f77-48e5-95b8-40c56f2c028b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pairs 1000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Pairs\",len(one_million))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e930a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Gaelic tokens: 14153438\n"
     ]
    }
   ],
   "source": [
    "total_gaelic_tokens = 0\n",
    "\n",
    "for path in file_paths:\n",
    "    with open(path, encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        sentences = get_gaelic_sentences(text, gaelic_words)\n",
    "        for sent in sentences:\n",
    "            tokens = tokenization(sent)\n",
    "            total_gaelic_tokens += len(tokens)\n",
    "\n",
    "print(\"Total Gaelic tokens:\", total_gaelic_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "189e86e0",
   "metadata": {
    "id": "189e86e0",
    "outputId": "4735cf76-f8a7-4195-dde7-0e2574babc7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['celt', '3193', '2.2', 'widener', 'hn'], 'zr1y'),\n",
       " (['3193', '2.2', 'widener', 'hn', 'zr1y'], '8'),\n",
       " (['2.2', 'widener', 'hn', 'zr1y', '8'], 'an'),\n",
       " (['widener', 'hn', 'zr1y', '8', 'an'], 'comh'),\n",
       " (['hn', 'zr1y', '8', 'an', 'comh'], '-'),\n",
       " (['zr1y', '8', 'an', 'comh', '-'], 'threoraiche'),\n",
       " (['8', 'an', 'comh', '-', 'threoraiche'], 'leaburan'),\n",
       " (['an', 'comh', '-', 'threoraiche', 'leaburan'], 'seou'),\n",
       " (['comh', '-', 'threoraiche', 'leaburan', 'seou'], 'a'),\n",
       " (['-', 'threoraiche', 'leaburan', 'seou', 'a'], 'chum')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0450e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
