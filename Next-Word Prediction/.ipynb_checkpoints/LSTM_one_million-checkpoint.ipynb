{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77da553",
   "metadata": {
    "id": "f77da553"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3182632",
   "metadata": {
    "id": "b3182632"
   },
   "source": [
    "#### one gla: 11727303 sets 14153438 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebabee5",
   "metadata": {
    "id": "1ebabee5"
   },
   "outputs": [],
   "source": [
    "ft = fasttext.load_model('../cc.gd.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa00f736",
   "metadata": {
    "id": "fa00f736"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"gd\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "nlp.max_length = 7000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed77acc",
   "metadata": {
    "id": "2ed77acc"
   },
   "outputs": [],
   "source": [
    "with open(\"gla_dictionary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gaelic_words = set(line.strip() for line in f if line.strip() != \"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf5eb00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bf5eb00",
    "outputId": "1ee152ba-ee07-410a-ebc3-6222132ca523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467b8389",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "467b8389",
    "outputId": "4e9b4b26-4d74-400c-b0bb-5b2259a07029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total .txt files found: 151\n"
     ]
    }
   ],
   "source": [
    "def get_txt_file_paths(folder):\n",
    "    txt_files = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                txt_files.append(os.path.join(root, file))\n",
    "    return txt_files\n",
    "\n",
    "file_paths = get_txt_file_paths(\"gla_books\")\n",
    "print(f\"Total .txt files found: {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95884f79",
   "metadata": {
    "id": "95884f79"
   },
   "outputs": [],
   "source": [
    "def tokenization(data):\n",
    "    doc = nlp(data)\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_space]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc90e8c",
   "metadata": {
    "id": "5bc90e8c"
   },
   "outputs": [],
   "source": [
    "def get_gaelic_sentences(text, gaelic_words, min_length=2, excluded_words=None):\n",
    "    if excluded_words is None:\n",
    "        excluded_words = {\"a\", \"i\", \"an\", \"is\", \"do\", \"so\"}\n",
    "\n",
    "    doc = nlp(text)\n",
    "    gaelic_sents = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        tokens = [token.text.lower() for token in sent if token.is_alpha]\n",
    "        for token in tokens:\n",
    "            if token in gaelic_words and token not in excluded_words:\n",
    "                gaelic_sents.append(sent.text.strip())\n",
    "                break\n",
    "    return gaelic_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7723923",
   "metadata": {
    "id": "e7723923"
   },
   "outputs": [],
   "source": [
    "class GlaDataset(Dataset):\n",
    "    def __init__(self, file_paths, gaelic_words, context_size=5):\n",
    "        self.pairs = []\n",
    "\n",
    "        for path in file_paths:\n",
    "            with open(path, encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                sentences = get_gaelic_sentences(text, gaelic_words)\n",
    "                for sent in sentences:\n",
    "                    tokens = tokenization(sent)\n",
    "                    if len(tokens) > context_size:\n",
    "                            for i in range(context_size, len(tokens)):\n",
    "                                context = tokens[i - context_size:i]\n",
    "                                target = tokens[i]\n",
    "                                self.pairs.append((context, target))\n",
    "    def  __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.pairs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f32480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "with open(\"one_million.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        dataset.append((item[\"context\"], item[\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8942adce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8942adce",
    "outputId": "ff802674-0f77-48e5-95b8-40c56f2c028b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pairs 1000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Pairs\",len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189e86e0",
   "metadata": {
    "id": "189e86e0",
    "outputId": "4735cf76-f8a7-4195-dde7-0e2574babc7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['feadh', 'na', 'dùthcha', ',', 'air'], 'nach'),\n",
       " ([\"'n\", 'a', 'choinnimh', ',', 'agus'], 'ghabh'),\n",
       " (['am', 'feum', 'sònruichte', 'a', 'dheanadh'], 'dàn'),\n",
       " (['agus', '12', 'an', 'déigh', 'so'], 'chaidh'),\n",
       " (['-', 'eigin', 'ann an', 'coslas', 'an'], 'duine'),\n",
       " (['eadar', 'am', 'bile', \"'s\", 'an'], 'deoch'),\n",
       " (['sibh', 'mar an ceudna', 'gu', 'dùth', '-'], 'ri'),\n",
       " ([':', 'le', 'gloinead', 'a', 'h'], '-'),\n",
       " (['the', 'gift', 'of', 'fred', 'norris'], 'robinson'),\n",
       " ([',', 'or', 'foinneamh', ',', '-an'], ',')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5f8db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for tokens, target in dataset:\n",
    "    counter.update(tokens)\n",
    "    counter.update([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "R35l1VTw8yRp",
   "metadata": {
    "id": "R35l1VTw8yRp"
   },
   "outputs": [],
   "source": [
    "N = 10000\n",
    "most_common_tokens = [token for token, _ in counter.most_common(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0_4AZxHq9DPL",
   "metadata": {
    "id": "0_4AZxHq9DPL"
   },
   "outputs": [],
   "source": [
    "def yield_tokens_limited(dataset, allowed_tokens):\n",
    "    allowed_set = set(allowed_tokens)\n",
    "    for context, target in dataset:\n",
    "        yield [token for token in context if token in allowed_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6523ecb3",
   "metadata": {
    "id": "6523ecb3"
   },
   "outputs": [],
   "source": [
    "vocab =build_vocab_from_iterator(\n",
    "    yield_tokens_limited(dataset, most_common_tokens), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced19a9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ced19a9f",
    "outputId": "d8fbc67b-3000-4d2e-8530-e30a0432ea0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84f8eadf",
   "metadata": {
    "id": "84f8eadf"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    context_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for context, target in batch:\n",
    "        context_ids = torch.tensor([vocab[token] for token in context], dtype=torch.long)\n",
    "        target_id = torch.tensor(vocab[target], dtype=torch.long)\n",
    "        context_batch.append(context_ids)\n",
    "        target_batch.append(target_id)\n",
    "\n",
    "    context_batch = torch.stack(context_batch)\n",
    "    target_batch = torch.stack(target_batch)\n",
    "\n",
    "    return context_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "258faf80",
   "metadata": {
    "id": "258faf80"
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "split_train, split_valid = train_test_split(train_dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b2791cd",
   "metadata": {
    "id": "6b2791cd"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(split_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch )\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9841513",
   "metadata": {
    "id": "d9841513"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "vocab_size = len(vocab)\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for idx, token in enumerate(vocab.get_itos()):\n",
    "    if token == \"<unk>\":\n",
    "        embedding_matrix[idx] = np.zeros(embedding_dim)\n",
    "    else:\n",
    "        embedding_matrix[idx] = ft.get_word_vector(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c28c26e",
   "metadata": {
    "id": "0c28c26e"
   },
   "outputs": [],
   "source": [
    "class NextWordPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        embedding_tensor = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "        self.embedding =  nn.Embedding.from_pretrained(embedding_tensor, freeze=False)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim,batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    def forward(self, input):\n",
    "        embedding = self.embedding(input)\n",
    "        lstm_out, (hidden_state, cell_state) = self.lstm(embedding)\n",
    "        last_hidden = hidden_state[-1]\n",
    "        dropped = self.dropout(last_hidden)\n",
    "        output = self.fc(dropped)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "747d7969",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "747d7969",
    "outputId": "b1b292c7-65f7-49f7-8a2d-3a123ad04907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextWordPredictor(\n",
       "  (embedding): Embedding(10001, 300)\n",
       "  (lstm): LSTM(300, 256, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=10001, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NextWordPredictor(\n",
    "    vocab_size = len(vocab),\n",
    "    embed_dim=embedding_dim,\n",
    "    hidden_dim=256,\n",
    ").to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6908cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b8432d2",
   "metadata": {
    "id": "7b8432d2"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56957901",
   "metadata": {
    "id": "56957901"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_function, device, topk=5):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    top1_correct = 0\n",
    "    topk_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for context_batch, target_batch in dataloader:\n",
    "            context_batch = context_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "            outputs = model(context_batch)\n",
    "            loss = loss_function(outputs, target_batch)\n",
    "            total_loss += loss.item() * target_batch.size(0)\n",
    "            \n",
    "            \n",
    "            preds = outputs.argmax(dim=1)\n",
    "            top1_correct += (preds == target_batch).sum().item()\n",
    "            \n",
    "            \n",
    "            topk_preds = torch.topk(outputs, topk, dim=1).indices\n",
    "            correct = topk_preds.eq(target_batch.view(-1, 1).expand_as(topk_preds))\n",
    "            topk_correct += correct.any(dim=1).sum().item()\n",
    "            \n",
    "            total_count += target_batch.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_count\n",
    "    accuracy = top1_correct / total_count\n",
    "    topk_accuracy = topk_correct / total_count\n",
    "    perplexity = math.exp(avg_loss)\n",
    "\n",
    "    return avg_loss, accuracy, topk_accuracy, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6492abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy(output, target, k=5):\n",
    "    topk_preds = torch.topk(output, k, dim=1).indices\n",
    "    correct = topk_preds.eq(target.view(-1, 1).expand_as(topk_preds))\n",
    "    return correct.any(dim=1).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd24468b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "bd24468b",
    "outputId": "654ca0bf-2e10-425d-a60e-3b5138f5c425",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 5.3582, Top-1 Accuracy: 0.2081, Top-5 Accuracy: 0.4244\n",
      "  Val   Loss: 5.0187, Top-1 Accuracy: 0.2001, Top-5 Accuracy: 0.4102, Perplexity: 151.2133\n",
      "Epoch 2:\n",
      "  Train Loss: 4.9244, Top-1 Accuracy: 0.2265, Top-5 Accuracy: 0.4515\n",
      "  Val   Loss: 4.8897, Top-1 Accuracy: 0.2091, Top-5 Accuracy: 0.4262, Perplexity: 132.9072\n",
      "Epoch 3:\n",
      "  Train Loss: 4.7626, Top-1 Accuracy: 0.2404, Top-5 Accuracy: 0.4704\n",
      "  Val   Loss: 4.8558, Top-1 Accuracy: 0.2136, Top-5 Accuracy: 0.4328, Perplexity: 128.4846\n",
      "Epoch 4:\n",
      "  Train Loss: 4.6408, Top-1 Accuracy: 0.2550, Top-5 Accuracy: 0.4896\n",
      "  Val   Loss: 4.8373, Top-1 Accuracy: 0.2140, Top-5 Accuracy: 0.4361, Perplexity: 126.1235\n",
      "Epoch 5:\n",
      "  Train Loss: 4.5349, Top-1 Accuracy: 0.2666, Top-5 Accuracy: 0.5064\n",
      "  Val   Loss: 4.8412, Top-1 Accuracy: 0.2157, Top-5 Accuracy: 0.4375, Perplexity: 126.6221\n",
      "Epoch 6:\n",
      "  Train Loss: 4.4385, Top-1 Accuracy: 0.2813, Top-5 Accuracy: 0.5229\n",
      "  Val   Loss: 4.8549, Top-1 Accuracy: 0.2164, Top-5 Accuracy: 0.4359, Perplexity: 128.3670\n"
     ]
    }
   ],
   "source": [
    "epochs = 6\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "val_perplexities = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for context_batch, target_batch in train_dataloader:\n",
    "        context_batch = context_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(context_batch)\n",
    "        loss = loss_function(outputs, target_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * target_batch.size(0)\n",
    "\n",
    "    train_loss = total_train_loss / len(train_dataloader.dataset)\n",
    "\n",
    "    train_loss_eval, train_acc, train_topk, train_ppl = evaluate(model, train_dataloader, loss_function, device, topk=5)\n",
    "    val_loss, val_acc, val_topk, val_ppl = evaluate(model, valid_dataloader, loss_function, device, topk=5)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_perplexities.append(val_ppl)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_nextword_model.pt\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Top-1 Accuracy: {train_acc:.4f}, Top-5 Accuracy: {train_topk:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}, Top-1 Accuracy: {val_acc:.4f}, Top-5 Accuracy: {val_topk:.4f}, Perplexity: {val_ppl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1548b235",
   "metadata": {
    "id": "1548b235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.2140\n",
      "Top-5 Accuracy: 0.4356\n",
      "Test Perplexity: 127.1386\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_nextword_model.pt\"))\n",
    "_, test_acc, test_topk, test_ppl = evaluate(model, test_dataloader, loss_function, device)\n",
    "print(f\"Top-1 Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Top-5 Accuracy: {test_topk:.4f}\")\n",
    "print(f\"Test Perplexity: {test_ppl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd6e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
